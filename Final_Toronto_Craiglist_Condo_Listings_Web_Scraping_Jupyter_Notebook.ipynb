{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "<h2 align = 'center'> Toronto Craiglist Rental Condo Web Scraping Project </h2>\n",
    "<h4 align = 'center'> Group Members: </h4>\n",
    "<h3 align = 'center'> Jessica Zhong, Barbara Chen, Vaughn Shideler, Karan Teckwani, Clover Guo, Rebecca Lam </h3>\n",
    "\n",
    "## -----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import urllib.request as urlrequest # Requesting the Website URL\n",
    "from urllib.parse import urlparse # Parse the URL\n",
    "from bs4 import BeautifulSoup # HTML parsing\n",
    "import re # Regular expressions\n",
    "from time import sleep # To prevent overwhelming the server between connections\n",
    "import numpy as np # Stacking the lists into a dataframe\n",
    "import pandas as pd # Creating a DataFrame from the stacked results\n",
    "import matplotlib.pyplot as plt # Data Visualization\n",
    "import seaborn as sns # Data Visualization\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build search criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final search url: https://toronto.craigslist.ca/search/hhh?query=condo&sort=rel\n"
     ]
    }
   ],
   "source": [
    "#Build search criteria\n",
    "\n",
    "search_query = 'condo'\n",
    "initial_url = 'https://toronto.craigslist.ca/'\n",
    "list_of_query_and_url = ['https://toronto.craigslist.ca/search/hhh?query=', search_query, '&sort=rel']\n",
    "\n",
    "# Join all of our strings together \n",
    "\n",
    "final_search_url = ''.join(list_of_query_and_url)\n",
    "print(\"Final search url: %s\" % (final_search_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build listing extractor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listing_extractor(website):\n",
    "    '''\n",
    "    Inputs: a URL from the listing on the search page\n",
    "            to investigate the listing and \n",
    "    Outputs: soup object\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        req = urlrequest.Request(website)\n",
    "        response = urlrequest.urlopen(req)\n",
    "        site = response.read()\n",
    "    except: \n",
    "        return   # Need this in case the website isn't there anymore or some other weird connection problem \n",
    "    \n",
    "    soup_obj = BeautifulSoup(site, 'html.parser') # Get the html from the site\n",
    "    \n",
    "    area = soup_obj.find(class_ = 'page-container') # Locating the page-container from the soub object\n",
    "    \n",
    "    return area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the final search url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_search_url_split_pages = urlparse(final_search_url) # Parse the URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating empty containers for regex Url's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_listing = []      # Regex seperation of all the rental listing\n",
    "sublet_listing = []      # Regex seperation of all the sublet listing\n",
    "shared_listing = []      # Regex seperation of all the shared listing\n",
    "sale_listing = []        # Regex seperation of all the sale listing\n",
    "other_listing = []       # Regex seperation of all the other listing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scraping all the listing url's from Craiglist condo query search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting page 1\n",
      "Getting page 2\n",
      "Getting page 3\n",
      "Getting page 4\n",
      "Getting page 5\n",
      "Getting page 6\n",
      "Getting page 7\n",
      "Getting page 8\n",
      "Getting page 9\n",
      "Getting page 10\n",
      "Getting page 11\n",
      "Getting page 12\n",
      "Getting page 13\n",
      "Getting page 14\n",
      "Getting page 15\n",
      "Getting page 16\n",
      "Getting page 17\n",
      "Getting page 18\n",
      "Getting page 19\n",
      "Getting page 20\n",
      "Getting page 21\n",
      "Done collecting the craiglist condo postings!\n",
      "There were 0 results found on each page.\n",
      "There were total of 0 listing url's found on craiglist condo search.\n",
      "There were total of 1665 rental listing url's found on craiglist condo search.\n",
      "There were total of 56 sublet listing url's found on craiglist condo search.\n",
      "There were total of 17 shared listing url's found on craiglist condo search.\n",
      "There were total of 662 sale listing url's found on craiglist condo search.\n",
      "There were total of 0 other listing url's found on craiglist condo search.\n"
     ]
    }
   ],
   "source": [
    "page_num = 21\n",
    "for page in range(1, min(page_num+1,999)): # Loop through all of our search result pages\n",
    "    print('Getting page', page)            # Print the current page number being scraped\n",
    "    if page == 1:                          # Loop to go to the next page upon scraping the first page\n",
    "        start_num = ''    \n",
    "    else:\n",
    "        start_num = str((page-1)*120)\n",
    "    \n",
    "    # search page url for each page\n",
    "    current_page = ''.join([final_search_url_split_pages.scheme,'://',\n",
    "                            final_search_url_split_pages.netloc ,\n",
    "                            final_search_url_split_pages.path ,'?','s=', \n",
    "                            start_num, '&', \n",
    "                            final_search_url_split_pages.query])  \n",
    "    \n",
    "    # Requesting the contents of each page and reading the page\n",
    "    req_each_page = urlrequest.Request(current_page)\n",
    "    response_each_page = urlrequest.urlopen(req_each_page)\n",
    "    read_each_page = response_each_page.read()\n",
    "        \n",
    "    # Creating the BeautifulSoup object of each page and finding the URL of each listing on that particular page    \n",
    "    soup_obj_of_each_page = BeautifulSoup(read_each_page, 'html.parser')\n",
    "    locating_each_url = soup_obj_of_each_page.findAll(\"li\", {\"class\" : \"result-row\"})\n",
    "    result_of_each_url = [result_row.find('a') for result_row in locating_each_url]\n",
    "    list_of_url = [str(result_row.get('href')) for result_row in result_of_each_url]\n",
    "    \n",
    "    # Regex search on the list of url to seperate the listing into different categories for refined data analysis\n",
    "    for eachurl in list_of_url:\n",
    "        rentals = re.search(r'https://toronto.craigslist.ca/\\w\\w\\w/apa/*', eachurl)\n",
    "        sublets = re.search(r'https://toronto.craigslist.ca/\\w\\w\\w/sub/*', eachurl)\n",
    "        shared = re.search(r'https://toronto.craigslist.ca/\\w\\w\\w/roo/*', eachurl)\n",
    "        sale = re.search(r'https://toronto.craigslist.ca/\\w\\w\\w/reb|o/*', eachurl)\n",
    "        if rentals:\n",
    "            rental_listing.append(eachurl)\n",
    "        elif sublets:\n",
    "            sublet_listing.append(eachurl)\n",
    "        elif shared:\n",
    "            shared_listing.append(eachurl)\n",
    "        elif sale:\n",
    "            sale_listing.append(eachurl)\n",
    "        else:\n",
    "            other_listing.append(eachurl)\n",
    "\n",
    "    sleep(1) # So that we don't be jerks.              \n",
    "\n",
    "print('Done collecting the craiglist condo postings!')\n",
    "print('There were %s results found on each page.' % (len(result_of_each_url)))\n",
    "print('There were total of %s listing url\\'s found on craiglist condo search.' % (len(list_of_url)))\n",
    "print('There were total of %s rental listing url\\'s found on craiglist condo search.' % (len(rental_listing)))\n",
    "print('There were total of %s sublet listing url\\'s found on craiglist condo search.' % (len(sublet_listing)))\n",
    "print('There were total of %s shared listing url\\'s found on craiglist condo search.' % (len(shared_listing)))\n",
    "print('There were total of %s sale listing url\\'s found on craiglist condo search.' % (len(sale_listing)))\n",
    "print('There were total of %s other listing url\\'s found on craiglist condo search.' % (len(other_listing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating empty containers for rental listing url's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_url = []                 # List of all the Rental Url scraped from the website\n",
    "rental_listing_id = []          # List of all the craiglist listing id's scraped from each rental url\n",
    "rental_price = []               # List of all the price information scraped from each rental url\n",
    "rental_layout = []              # List of all the layout information scraped from each rental url\n",
    "rental_bedroom = []             # List of all the bedroom information scraped from each rental url\n",
    "rental_bathroom = []            # List of all the bathroom information scraped from each rental url\n",
    "rental_sqft = []                # List of all the square feet information scraped from each rental url\n",
    "rental_description = []         # List of all the description information scraped from each rental url\n",
    "rental_latitude = []            # List of all the latitude information scraped from each rental url\n",
    "rental_longitude = []           # List of all the longitude information scraped from each rental url\n",
    "rental_map_text = []            # List of all the map text information scraped from each rental url\n",
    "rental_google_map_url = []      # List of all the google map url information scraped from each rental url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scraping all the rental listing url's from rental_listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 1665 rental url's scraped.\n",
      "There were 1665 rental listing id's scraped.\n",
      "There were 1665 rental price scraped.\n",
      "There were 1665 rental layout scraped.\n",
      "There were 1665 rental bedroom scraped.\n",
      "There were 1665 rental bathroom scraped.\n",
      "There were 1665 rental square feet scraped.\n",
      "There were 1665 rental description scraped.\n",
      "There were 1665 rental latitude scraped.\n",
      "There were 1665 rental longitude scraped.\n",
      "There were 1665 rental map text scraped.\n",
      "There were 1665 rental google map url scraped.\n"
     ]
    }
   ],
   "source": [
    "# Scraping the content of each url on the search page from the rental listing   \n",
    "for rentalurl in range(len(rental_listing)):\n",
    "    information = listing_extractor(rental_listing[rentalurl])\n",
    "    rental_url.append(rental_listing[rentalurl])\n",
    "    \n",
    "    # Extracting the craiglist listing ID of each individual listing\n",
    "    try:\n",
    "        posting_info = information.find(\"div\", {\"class\":\"postinginfos\"})\n",
    "        locate_id = posting_info.find(\"p\",{\"class\":\"postinginfo\"})\n",
    "        id_only = re.findall(r'\\d+', locate_id.text)\n",
    "        result = '%s' % \"','\".join(id_only)\n",
    "        if result:\n",
    "            rental_listing_id.append(result)\n",
    "    except:\n",
    "        no_id = 'Missing_Data' \n",
    "        rental_listing_id.append(no_id)\n",
    "    \n",
    "    # Extracting the price of each individual listing\n",
    "    try:\n",
    "        price_info = information.find(\"span\", {\"class\":\"price\"}).string\n",
    "        only_price = re.findall(r'\\d+', price_info)\n",
    "        if only_price:\n",
    "            rental_price.append(only_price[0])\n",
    "    except:\n",
    "        no_price = 'Missing_Data'\n",
    "        rental_price.append(no_price)\n",
    "            \n",
    "    # Extracting the layout of each individual listing\n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        only_layout = layout_info[0].text\n",
    "        if only_layout:\n",
    "            rental_layout.append(only_layout)\n",
    "    except:\n",
    "        no_layout = 'Missing_Data'\n",
    "        rental_layout.append(no_layout)\n",
    "    \n",
    "    # Extracting the bedroom of each individual listing\n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        only_layout = layout_info[0].text\n",
    "        regex_layout = re.findall(r'\\d+', only_layout)\n",
    "        if regex_layout:\n",
    "            bedroom_info = regex_layout[0]\n",
    "            rental_bedroom.append(bedroom_info)\n",
    "    except:\n",
    "        no_bedroom = 'Missing_Data'\n",
    "        rental_bedroom.append(no_bedroom)\n",
    "        \n",
    "    # Extracting the bathroom of each individual listing\n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        only_layout = layout_info[0].text\n",
    "        regex_layout = re.findall(r'\\d+', only_layout)\n",
    "        if regex_layout:\n",
    "            bathroom_info = regex_layout[1]\n",
    "            rental_bathroom.append(bathroom_info)\n",
    "    except:\n",
    "        no_bathroom = 'Missing_Data'\n",
    "        rental_bathroom.append(no_bathroom)\n",
    "    \n",
    "    # Extracting the square feet of each individual listing \n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        squarefeet_info = layout_info[1].text\n",
    "        regex_sqft = re.findall(r'\\d{3,4}ft\\d', squarefeet_info)\n",
    "        if regex_sqft:\n",
    "            only_sqft = re.findall(r'\\d+', regex_sqft[0])\n",
    "            if only_sqft:\n",
    "                rental_sqft.append(only_sqft[0])\n",
    "        else:\n",
    "            try:\n",
    "                description_information = information.find(\"section\",\n",
    "                                                           {\"id\" :\"postingbody\"}).findAll(text=True,\n",
    "                                                                                          recursive=False)                          \n",
    "                description_info = ''.join(description_information)\n",
    "                initial_regex_search = re.findall(r'(\\d{3,4}|\\d+[\\,]?\\d+)[\\s]?[S|s][q|f]', description_info)\n",
    "                if initial_regex_search:\n",
    "                    rental_sqft.append(initial_regex_search[0])\n",
    "                else:\n",
    "                    second_regex_search = re.findall(r'\\w+[\\s]?\\w+[\\s]?:[\\s]?\\d+[-]?\\d+', description_info)\n",
    "                    if second_regex_search:\n",
    "                        regex_digits_only = re.findall(r'\\d+[-]?\\d+', second_regex_search)\n",
    "                        if regex_digits_only:\n",
    "                            rental_sqft.append(regex_digits_only[0])\n",
    "                        else:\n",
    "                            no_regex_digits = \"Missing_Data\"\n",
    "                            rental_sqft.append(no_regex_digits)\n",
    "                    else:\n",
    "                        no_second_regex_search = \"Missing_Data\"\n",
    "                        rental_sqft.append(no_second_regex_search)\n",
    "            except:\n",
    "                no_description = 'Missing_Data'\n",
    "                rental_sqft.append(no_description)\n",
    "    except:\n",
    "        no_listing = 'Missing_Data'\n",
    "        rental_sqft.append(no_listing)\n",
    "        \n",
    "    # Extracting the latitude of each individual listing\n",
    "    try:\n",
    "        location_info = information.find(\"div\",{\"class\": \"viewposting\"})\n",
    "        latitude_info = location_info.get(\"data-latitude\")\n",
    "        if latitude_info:\n",
    "            rental_latitude.append(latitude_info)\n",
    "    except:\n",
    "        no_latitude_info = 'Missing_Data'\n",
    "        rental_latitude.append(no_latitude_info)\n",
    "                \n",
    "    # Extracting the longitude of each individual listing    \n",
    "    try:\n",
    "        longitude_info = location_info.get(\"data-longitude\")\n",
    "        if longitude_info:\n",
    "            rental_longitude.append(longitude_info)\n",
    "    except:\n",
    "        no_longitude_info = 'Missing_Data'\n",
    "        rental_longitude.append(no_longitude_info)\n",
    "            \n",
    "    # Extracting the text below map of each individual listing\n",
    "    try:\n",
    "        map_text_info = information.find(\"div\",{\"class\":\"mapaddress\"})\n",
    "        only_map_text = map_text_info.text\n",
    "        if only_map_text:\n",
    "            rental_map_text.append(only_map_text)\n",
    "    except:\n",
    "        no_map_text = \"Missing_Data\"\n",
    "        rental_map_text.append(no_map_text)\n",
    "                \n",
    "    # Extracting the text below map of each individual listing\n",
    "    try:\n",
    "        google_map_url_info = information.find(\"p\",{\"class\":\"mapaddress\"})\n",
    "        only_google_map_url = google_map_url_info.find(\"a\").get(\"href\")\n",
    "        if only_google_map_url:\n",
    "            rental_google_map_url.append(only_google_map_url)\n",
    "    except:\n",
    "        no_google_map_url = 'Missing_Data'\n",
    "        rental_google_map_url.append(no_google_map_url)\n",
    "    \n",
    "    # Extracting the description of each individual listing \n",
    "    try:\n",
    "        description_information = information.find(\"section\",{\"id\" :\"postingbody\"}).findAll(text=True, recursive=False)                          \n",
    "        description_info = ''.join(description_information)\n",
    "        if description_info:\n",
    "            rental_description.append(description_info)\n",
    "    except:\n",
    "        no_description = \"Missing_Data\"\n",
    "        rental_description.append(no_description)\n",
    "    \n",
    "    sleep(2)\n",
    "\n",
    "print('There were %s rental url\\'s scraped.' % (len(rental_url)))\n",
    "print('There were %s rental listing id\\'s scraped.' % (len(rental_listing_id)))   \n",
    "print('There were %s rental price scraped.' % (len(rental_price)))\n",
    "print('There were %s rental layout scraped.' % (len(rental_layout)))\n",
    "print('There were %s rental bedroom scraped.' % (len(rental_bedroom))) \n",
    "print('There were %s rental bathroom scraped.' % (len(rental_bathroom)))\n",
    "print('There were %s rental square feet scraped.' % (len(rental_sqft)))\n",
    "print('There were %s rental description scraped.' % (len(rental_description)))\n",
    "print('There were %s rental latitude scraped.' % (len(rental_latitude)))\n",
    "print('There were %s rental longitude scraped.' % (len(rental_longitude))) \n",
    "print('There were %s rental map text scraped.' % (len(rental_map_text))) \n",
    "print('There were %s rental google map url scraped.' % (len(rental_google_map_url))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataframe using pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "craiglist_rental_dataset = pd.DataFrame(np.column_stack([rental_listing_id, rental_price, rental_layout, \n",
    "                                                         rental_bedroom, rental_bathroom, rental_sqft, \n",
    "                                                         rental_latitude, rental_longitude, rental_url, \n",
    "                                                         rental_map_text, rental_google_map_url, \n",
    "                                                         rental_description]),\n",
    "                                        columns = ['rental_listing_id','rental_price', 'rental_layout',\n",
    "                                                   'rental_bedroom', 'rental_bathroom', 'rental_sqft', \n",
    "                                                   'rental_latitude', 'rental_longitude', 'rental_url', \n",
    "                                                   'rental_map_text', 'rental_google_map_url', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_listing_id</th>\n",
       "      <th>rental_price</th>\n",
       "      <th>rental_layout</th>\n",
       "      <th>rental_bedroom</th>\n",
       "      <th>rental_bathroom</th>\n",
       "      <th>rental_sqft</th>\n",
       "      <th>rental_latitude</th>\n",
       "      <th>rental_longitude</th>\n",
       "      <th>rental_url</th>\n",
       "      <th>rental_map_text</th>\n",
       "      <th>rental_google_map_url</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6466154515</td>\n",
       "      <td>1048</td>\n",
       "      <td>1BR / 1Ba</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>https://toronto.craigslist.ca/drh/apa/d/great-...</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>\\n\\nI have a nice 1 bedroom, 1 bath condo for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6466158349</td>\n",
       "      <td>1075</td>\n",
       "      <td>2BR / 1Ba</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>https://toronto.craigslist.ca/mss/apa/d/huge-2...</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>\\n\\nI have a nice 2 bedroom, 1 bath condo apar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6466159554</td>\n",
       "      <td>1275</td>\n",
       "      <td>3BR / 2Ba</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/apa/d/3-bedr...</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>\\n\\nI have a nice 3 bedroom, 1.5 bath apartmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6466161138</td>\n",
       "      <td>895</td>\n",
       "      <td>2BR / 1Ba</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/apa/d/great-...</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>\\n\\nI have a nice 2 bedroom, 1 bath condo+den....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6466163942</td>\n",
       "      <td>1125</td>\n",
       "      <td>2BR / 1Ba</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>https://toronto.craigslist.ca/bra/apa/d/nice-2...</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>\\n\\nI have a nice 2 bedroom, 1 bath Condo in b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rental_listing_id rental_price rental_layout rental_bedroom rental_bathroom  \\\n",
       "0        6466154515         1048     1BR / 1Ba              1               1   \n",
       "1        6466158349         1075     2BR / 1Ba              2               1   \n",
       "2        6466159554         1275     3BR / 2Ba              3               2   \n",
       "3        6466161138          895     2BR / 1Ba              2               1   \n",
       "4        6466163942         1125     2BR / 1Ba              2               1   \n",
       "\n",
       "    rental_sqft rental_latitude rental_longitude  \\\n",
       "0  Missing_Data    Missing_Data     Missing_Data   \n",
       "1  Missing_Data    Missing_Data     Missing_Data   \n",
       "2  Missing_Data    Missing_Data     Missing_Data   \n",
       "3  Missing_Data    Missing_Data     Missing_Data   \n",
       "4  Missing_Data    Missing_Data     Missing_Data   \n",
       "\n",
       "                                          rental_url rental_map_text  \\\n",
       "0  https://toronto.craigslist.ca/drh/apa/d/great-...    Missing_Data   \n",
       "1  https://toronto.craigslist.ca/mss/apa/d/huge-2...    Missing_Data   \n",
       "2  https://toronto.craigslist.ca/tor/apa/d/3-bedr...    Missing_Data   \n",
       "3  https://toronto.craigslist.ca/tor/apa/d/great-...    Missing_Data   \n",
       "4  https://toronto.craigslist.ca/bra/apa/d/nice-2...    Missing_Data   \n",
       "\n",
       "  rental_google_map_url                                        description  \n",
       "0          Missing_Data  \\n\\nI have a nice 1 bedroom, 1 bath condo for ...  \n",
       "1          Missing_Data  \\n\\nI have a nice 2 bedroom, 1 bath condo apar...  \n",
       "2          Missing_Data  \\n\\nI have a nice 3 bedroom, 1.5 bath apartmen...  \n",
       "3          Missing_Data  \\n\\nI have a nice 2 bedroom, 1 bath condo+den....  \n",
       "4          Missing_Data  \\n\\nI have a nice 2 bedroom, 1 bath Condo in b...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "craiglist_rental_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_listing_id</th>\n",
       "      <th>rental_price</th>\n",
       "      <th>rental_layout</th>\n",
       "      <th>rental_bedroom</th>\n",
       "      <th>rental_bathroom</th>\n",
       "      <th>rental_sqft</th>\n",
       "      <th>rental_latitude</th>\n",
       "      <th>rental_longitude</th>\n",
       "      <th>rental_url</th>\n",
       "      <th>rental_map_text</th>\n",
       "      <th>rental_google_map_url</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>6460406155</td>\n",
       "      <td>2400</td>\n",
       "      <td>1BR / 1Ba</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>550</td>\n",
       "      <td>43.641638</td>\n",
       "      <td>-79.380944</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/apa/d/fully-...</td>\n",
       "      <td>12 York St</td>\n",
       "      <td>https://maps.google.com/?q=loc%3A+%31%32+York+...</td>\n",
       "      <td>\\n\\nFully Furnished Executive 1 Bedroom + Stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>6460385370</td>\n",
       "      <td>2280</td>\n",
       "      <td>1BR / 1Ba</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>550</td>\n",
       "      <td>43.641093</td>\n",
       "      <td>-79.380324</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/apa/d/brand-...</td>\n",
       "      <td>88 Harbour St</td>\n",
       "      <td>https://maps.google.com/?q=loc%3A+%38%38+Harbo...</td>\n",
       "      <td>\\n\\nBrand New Open Concept 1 B! One Of The Bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>6460379347</td>\n",
       "      <td>1900</td>\n",
       "      <td>1BR / 1Ba</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>43.822700</td>\n",
       "      <td>-79.394600</td>\n",
       "      <td>https://toronto.craigslist.ca/yrk/apa/d/fully-...</td>\n",
       "      <td>7171 yonge st</td>\n",
       "      <td>https://maps.google.com/?q=loc%3A+%37%31%37%31...</td>\n",
       "      <td>\\n\\nFully furnished 1+den condo, high floor, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>6460381895</td>\n",
       "      <td>2250</td>\n",
       "      <td>2BR / 2Ba</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>850</td>\n",
       "      <td>43.624511</td>\n",
       "      <td>-79.489637</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/apa/d/gorgeo...</td>\n",
       "      <td>165 Legion Rd N</td>\n",
       "      <td>https://maps.google.com/?q=loc%3A+%31%36%35+Le...</td>\n",
       "      <td>\\n\\nGorgeous Two Bedroom 2 Bath Condo (The Cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>6460378210</td>\n",
       "      <td>2200</td>\n",
       "      <td>1BR / 1Ba</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>750</td>\n",
       "      <td>43.667778</td>\n",
       "      <td>-79.391005</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/apa/d/beauti...</td>\n",
       "      <td>110 Charles St</td>\n",
       "      <td>https://maps.google.com/?q=loc%3A+%31%31%30+Ch...</td>\n",
       "      <td>\\n\\nBeautifully Maintained One Bedroom + Den S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rental_listing_id rental_price rental_layout rental_bedroom  \\\n",
       "1660        6460406155         2400     1BR / 1Ba              1   \n",
       "1661        6460385370         2280     1BR / 1Ba              1   \n",
       "1662        6460379347         1900     1BR / 1Ba              1   \n",
       "1663        6460381895         2250     2BR / 2Ba              2   \n",
       "1664        6460378210         2200     1BR / 1Ba              1   \n",
       "\n",
       "     rental_bathroom   rental_sqft rental_latitude rental_longitude  \\\n",
       "1660               1           550       43.641638       -79.380944   \n",
       "1661               1           550       43.641093       -79.380324   \n",
       "1662               1  Missing_Data       43.822700       -79.394600   \n",
       "1663               2           850       43.624511       -79.489637   \n",
       "1664               1           750       43.667778       -79.391005   \n",
       "\n",
       "                                             rental_url  rental_map_text  \\\n",
       "1660  https://toronto.craigslist.ca/tor/apa/d/fully-...       12 York St   \n",
       "1661  https://toronto.craigslist.ca/tor/apa/d/brand-...    88 Harbour St   \n",
       "1662  https://toronto.craigslist.ca/yrk/apa/d/fully-...    7171 yonge st   \n",
       "1663  https://toronto.craigslist.ca/tor/apa/d/gorgeo...  165 Legion Rd N   \n",
       "1664  https://toronto.craigslist.ca/tor/apa/d/beauti...   110 Charles St   \n",
       "\n",
       "                                  rental_google_map_url  \\\n",
       "1660  https://maps.google.com/?q=loc%3A+%31%32+York+...   \n",
       "1661  https://maps.google.com/?q=loc%3A+%38%38+Harbo...   \n",
       "1662  https://maps.google.com/?q=loc%3A+%37%31%37%31...   \n",
       "1663  https://maps.google.com/?q=loc%3A+%31%36%35+Le...   \n",
       "1664  https://maps.google.com/?q=loc%3A+%31%31%30+Ch...   \n",
       "\n",
       "                                            description  \n",
       "1660  \\n\\nFully Furnished Executive 1 Bedroom + Stud...  \n",
       "1661  \\n\\nBrand New Open Concept 1 B! One Of The Bes...  \n",
       "1662  \\n\\nFully furnished 1+den condo, high floor, p...  \n",
       "1663  \\n\\nGorgeous Two Bedroom 2 Bath Condo (The Cal...  \n",
       "1664  \\n\\nBeautifully Maintained One Bedroom + Den S...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "craiglist_rental_dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the DataFrame into Excel file to store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "craiglist_rental_dataset.to_excel(\"Final_Toronto_Craiglist_Condo_Rental_dataset_Jan_20.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating empty containers for sublet listing url's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sublet_url = []                 # List of all the sublet Url scraped from the website\n",
    "sublet_listing_id = []          # List of all the craiglist listing id's scraped from each sublet url\n",
    "sublet_price = []               # List of all the price information scraped from each sublet url\n",
    "sublet_layout = []              # List of all the layout information scraped from each sublet url\n",
    "sublet_bedroom = []             # List of all the bedroom information scraped from each sublet url\n",
    "sublet_bathroom = []            # List of all the bathroom information scraped from each sublet url\n",
    "sublet_sqft = []                # List of all the square feet information scraped from each sublet url\n",
    "sublet_description = []         # List of all the description information scraped from each sublet url\n",
    "sublet_latitude = []            # List of all the latitude information scraped from each sublet url\n",
    "sublet_longitude = []           # List of all the longitude information scraped from each sublet url\n",
    "sublet_map_text = []            # List of all the map text information scraped from each sublet url\n",
    "sublet_google_map_url = []      # List of all the google map url information scraped from each sublet url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scraping all the sublet listing url's from sublet_listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 56 sublet url's scraped.\n",
      "There were 56 sublet listing id's scraped.\n",
      "There were 56 sublet price scraped.\n",
      "There were 56 sublet layout scraped.\n",
      "There were 56 sublet bedroom scraped.\n",
      "There were 56 sublet bathroom scraped.\n",
      "There were 56 sublet square feet scraped.\n",
      "There were 56 sublet description scraped.\n",
      "There were 56 sublet latitude scraped.\n",
      "There were 56 sublet longitude scraped.\n",
      "There were 56 sublet map text scraped.\n",
      "There were 56 sublet google map url scraped.\n"
     ]
    }
   ],
   "source": [
    "# Scraping the content of each url on the search page from the sublet listing   \n",
    "for subleturl in range(len(sublet_listing)):\n",
    "    information = listing_extractor(sublet_listing[subleturl])\n",
    "    sublet_url.append(sublet_listing[subleturl])\n",
    "    \n",
    "    # Extracting the craiglist listing ID of each individual listing\n",
    "    try:\n",
    "        posting_info = information.find(\"div\", {\"class\":\"postinginfos\"})\n",
    "        locate_id = posting_info.find(\"p\",{\"class\":\"postinginfo\"})\n",
    "        id_only = re.findall(r'\\d+', locate_id.text)\n",
    "        result = '%s' % \"','\".join(id_only)\n",
    "        if result:\n",
    "            sublet_listing_id.append(result)\n",
    "    except:\n",
    "        no_id = 'Missing_Data' \n",
    "        sublet_listing_id.append(no_id)\n",
    "    \n",
    "    # Extracting the price of each individual listing\n",
    "    try:\n",
    "        price_info = information.find(\"span\", {\"class\":\"price\"}).string\n",
    "        only_price = re.findall(r'\\d+', price_info)\n",
    "        if only_price:\n",
    "            sublet_price.append(only_price[0])\n",
    "    except:\n",
    "        no_price = 'Missing_Data'\n",
    "        sublet_price.append(no_price)\n",
    "            \n",
    "    # Extracting the layout of each individual listing\n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        only_layout = layout_info[0].text\n",
    "        if only_layout:\n",
    "            sublet_layout.append(only_layout)\n",
    "    except:\n",
    "        no_layout = 'Missing_Data'\n",
    "        sublet_layout.append(no_layout)\n",
    "    \n",
    "    # Extracting the bedroom of each individual listing\n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        only_layout = layout_info[0].text\n",
    "        regex_layout = re.findall(r'\\d+', only_layout)\n",
    "        if regex_layout:\n",
    "            bedroom_info = regex_layout[0]\n",
    "            sublet_bedroom.append(bedroom_info)\n",
    "    except:\n",
    "        no_bedroom = 'Missing_Data'\n",
    "        sublet_bedroom.append(no_bedroom)\n",
    "        \n",
    "    # Extracting the bathroom of each individual listing\n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        only_layout = layout_info[0].text\n",
    "        regex_layout = re.findall(r'\\d+', only_layout)\n",
    "        if regex_layout:\n",
    "            bathroom_info = regex_layout[1]\n",
    "            sublet_bathroom.append(bathroom_info)\n",
    "    except:\n",
    "        no_bathroom = 'Missing_Data'\n",
    "        sublet_bathroom.append(no_bathroom)\n",
    "    \n",
    "    # Extracting the square feet of each individual listing \n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        squarefeet_info = layout_info[1].text\n",
    "        regex_sqft = re.findall(r'\\d{3,4}ft\\d', squarefeet_info)\n",
    "        if regex_sqft:\n",
    "            only_sqft = re.findall(r'\\d+', regex_sqft[0])\n",
    "            if only_sqft:\n",
    "                sublet_sqft.append(only_sqft[0])\n",
    "        else:\n",
    "            try:\n",
    "                description_information = information.find(\"section\",\n",
    "                                                           {\"id\" :\"postingbody\"}).findAll(text=True,\n",
    "                                                                                          recursive=False)                          \n",
    "                description_info = ''.join(description_information)\n",
    "                initial_regex_search = re.findall(r'(\\d{3,4}|\\d+[\\,]?\\d+)[\\s]?[S|s][q|f]', description_info)\n",
    "                if initial_regex_search:\n",
    "                    sublet_sqft.append(initial_regex_search[0])\n",
    "                else:\n",
    "                    second_regex_search = re.findall(r'\\w+[\\s]?\\w+[\\s]?:[\\s]?\\d+[-]?\\d+', description_info)\n",
    "                    if second_regex_search:\n",
    "                        regex_digits_only = re.findall(r'\\d+[-]?\\d+', second_regex_search)\n",
    "                        if regex_digits_only:\n",
    "                            sublet_sqft.append(regex_digits_only[0])\n",
    "                        else:\n",
    "                            no_regex_digits = \"Missing_Data\"\n",
    "                            sublet_sqft.append(no_regex_digits)\n",
    "                    else:\n",
    "                        no_second_regex_search = \"Missing_Data\"\n",
    "                        sublet_sqft.append(no_second_regex_search)\n",
    "            except:\n",
    "                no_description = 'Missing_Data'\n",
    "                sublet_sqft.append(no_description)\n",
    "    except:\n",
    "        no_listing = 'Missing_Data'\n",
    "        sublet_sqft.append(no_listing)\n",
    "        \n",
    "    # Extracting the latitude of each individual listing\n",
    "    try:\n",
    "        location_info = information.find(\"div\",{\"class\": \"viewposting\"})\n",
    "        latitude_info = location_info.get(\"data-latitude\")\n",
    "        if latitude_info:\n",
    "            sublet_latitude.append(latitude_info)\n",
    "    except:\n",
    "        no_latitude_info = 'Missing_Data'\n",
    "        sublet_latitude.append(no_latitude_info)\n",
    "                \n",
    "    # Extracting the longitude of each individual listing    \n",
    "    try:\n",
    "        longitude_info = location_info.get(\"data-longitude\")\n",
    "        if longitude_info:\n",
    "            sublet_longitude.append(longitude_info)\n",
    "    except:\n",
    "        no_longitude_info = 'Missing_Data'\n",
    "        sublet_longitude.append(no_longitude_info)\n",
    "            \n",
    "    # Extracting the text below map of each individual listing\n",
    "    try:\n",
    "        map_text_info = information.find(\"div\",{\"class\":\"mapaddress\"})\n",
    "        only_map_text = map_text_info.text\n",
    "        if only_map_text:\n",
    "            sublet_map_text.append(only_map_text)\n",
    "    except:\n",
    "        no_map_text = \"Missing_Data\"\n",
    "        sublet_map_text.append(no_map_text)\n",
    "                \n",
    "    # Extracting the text below map of each individual listing\n",
    "    try:\n",
    "        google_map_url_info = information.find(\"p\",{\"class\":\"mapaddress\"})\n",
    "        only_google_map_url = google_map_url_info.find(\"a\").get(\"href\")\n",
    "        if only_google_map_url:\n",
    "            sublet_google_map_url.append(only_google_map_url)\n",
    "    except:\n",
    "        no_google_map_url = 'Missing_Data'\n",
    "        sublet_google_map_url.append(no_google_map_url)\n",
    "    \n",
    "    # Extracting the description of each individual listing \n",
    "    try:\n",
    "        description_information = information.find(\"section\",{\"id\" :\"postingbody\"}).findAll(text=True, recursive=False)                          \n",
    "        description_info = ''.join(description_information)\n",
    "        if description_info:\n",
    "            sublet_description.append(description_info)\n",
    "    except:\n",
    "        no_description = \"Missing_Data\"\n",
    "        sublet_description.append(no_description)\n",
    "    \n",
    "    sleep(2)\n",
    "\n",
    "print('There were %s sublet url\\'s scraped.' % (len(sublet_url)))\n",
    "print('There were %s sublet listing id\\'s scraped.' % (len(sublet_listing_id)))   \n",
    "print('There were %s sublet price scraped.' % (len(sublet_price)))\n",
    "print('There were %s sublet layout scraped.' % (len(sublet_layout)))\n",
    "print('There were %s sublet bedroom scraped.' % (len(sublet_bedroom))) \n",
    "print('There were %s sublet bathroom scraped.' % (len(sublet_bathroom)))\n",
    "print('There were %s sublet square feet scraped.' % (len(sublet_sqft)))\n",
    "print('There were %s sublet description scraped.' % (len(sublet_description)))\n",
    "print('There were %s sublet latitude scraped.' % (len(sublet_latitude)))\n",
    "print('There were %s sublet longitude scraped.' % (len(sublet_longitude))) \n",
    "print('There were %s sublet map text scraped.' % (len(sublet_map_text))) \n",
    "print('There were %s sublet google map url scraped.' % (len(sublet_google_map_url))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataframe using pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "craiglist_sublet_dataset = pd.DataFrame(np.column_stack([sublet_listing_id, sublet_price, sublet_layout, \n",
    "                                                         sublet_bedroom, sublet_bathroom, sublet_sqft, \n",
    "                                                         sublet_latitude, sublet_longitude, sublet_url, \n",
    "                                                         sublet_map_text, sublet_google_map_url, \n",
    "                                                         sublet_description]),\n",
    "                                        columns = ['sublet_listing_id','sublet_price', 'sublet_layout',\n",
    "                                                   'sublet_bedroom', 'sublet_bathroom', 'sublet_sqft', \n",
    "                                                   'sublet_latitude', 'sublet_longitude', 'sublet_url', \n",
    "                                                   'sublet_map_text', 'sublet_google_map_url', 'sublet_description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the DataFrame into Excel file to store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "craiglist_sublet_dataset.to_excel(\"Final_Toronto_Craiglist_Condo_Sublet_dataset_Jan_20.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sublet_listing_id</th>\n",
       "      <th>sublet_price</th>\n",
       "      <th>sublet_layout</th>\n",
       "      <th>sublet_bedroom</th>\n",
       "      <th>sublet_bathroom</th>\n",
       "      <th>sublet_sqft</th>\n",
       "      <th>sublet_latitude</th>\n",
       "      <th>sublet_longitude</th>\n",
       "      <th>sublet_url</th>\n",
       "      <th>sublet_map_text</th>\n",
       "      <th>sublet_google_map_url</th>\n",
       "      <th>sublet_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6465968265</td>\n",
       "      <td>2375</td>\n",
       "      <td>1BR / 1Ba</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>600</td>\n",
       "      <td>43.671813</td>\n",
       "      <td>-79.388104</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/sub/d/yorkvi...</td>\n",
       "      <td>18 Yorkville Ave</td>\n",
       "      <td>https://maps.google.com/?q=loc%3A+%31%38+Yorkv...</td>\n",
       "      <td>\\n\\nLOCATION: \\nGorgeous Condo In An Exclusive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6465949142</td>\n",
       "      <td>80</td>\n",
       "      <td>available jan 19</td>\n",
       "      <td>19</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>43.722300</td>\n",
       "      <td>-79.450400</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/sub/d/execut...</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>https://maps.google.com/maps/preview/@43.72230...</td>\n",
       "      <td>\\n\\nThis is a Much Better Alternative to Hotel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6465963479</td>\n",
       "      <td>50</td>\n",
       "      <td>available jan 19</td>\n",
       "      <td>19</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>43.722300</td>\n",
       "      <td>-79.450400</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/sub/d/small-...</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>https://maps.google.com/maps/preview/@43.72230...</td>\n",
       "      <td>\\n\\nThis is a much better alternative to hotel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6465959712</td>\n",
       "      <td>60</td>\n",
       "      <td>available jan 19</td>\n",
       "      <td>19</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>43.722300</td>\n",
       "      <td>-79.450400</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/sub/d/clean-...</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>https://maps.google.com/maps/preview/@43.72230...</td>\n",
       "      <td>\\n\\nThis is a Much Better Alternative to Hotel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6465953687</td>\n",
       "      <td>170</td>\n",
       "      <td>available jan 19</td>\n",
       "      <td>19</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>43.722300</td>\n",
       "      <td>-79.450400</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/sub/d/furnis...</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>https://maps.google.com/maps/preview/@43.72230...</td>\n",
       "      <td>\\n\\nThe Entire Suite is fully furnished. \\nThi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sublet_listing_id sublet_price     sublet_layout sublet_bedroom  \\\n",
       "0        6465968265         2375         1BR / 1Ba              1   \n",
       "1        6465949142           80  available jan 19             19   \n",
       "2        6465963479           50  available jan 19             19   \n",
       "3        6465959712           60  available jan 19             19   \n",
       "4        6465953687          170  available jan 19             19   \n",
       "\n",
       "  sublet_bathroom   sublet_sqft sublet_latitude sublet_longitude  \\\n",
       "0               1           600       43.671813       -79.388104   \n",
       "1    Missing_Data  Missing_Data       43.722300       -79.450400   \n",
       "2    Missing_Data  Missing_Data       43.722300       -79.450400   \n",
       "3    Missing_Data  Missing_Data       43.722300       -79.450400   \n",
       "4    Missing_Data  Missing_Data       43.722300       -79.450400   \n",
       "\n",
       "                                          sublet_url   sublet_map_text  \\\n",
       "0  https://toronto.craigslist.ca/tor/sub/d/yorkvi...  18 Yorkville Ave   \n",
       "1  https://toronto.craigslist.ca/tor/sub/d/execut...      Missing_Data   \n",
       "2  https://toronto.craigslist.ca/tor/sub/d/small-...      Missing_Data   \n",
       "3  https://toronto.craigslist.ca/tor/sub/d/clean-...      Missing_Data   \n",
       "4  https://toronto.craigslist.ca/tor/sub/d/furnis...      Missing_Data   \n",
       "\n",
       "                               sublet_google_map_url  \\\n",
       "0  https://maps.google.com/?q=loc%3A+%31%38+Yorkv...   \n",
       "1  https://maps.google.com/maps/preview/@43.72230...   \n",
       "2  https://maps.google.com/maps/preview/@43.72230...   \n",
       "3  https://maps.google.com/maps/preview/@43.72230...   \n",
       "4  https://maps.google.com/maps/preview/@43.72230...   \n",
       "\n",
       "                                  sublet_description  \n",
       "0  \\n\\nLOCATION: \\nGorgeous Condo In An Exclusive...  \n",
       "1  \\n\\nThis is a Much Better Alternative to Hotel...  \n",
       "2  \\n\\nThis is a much better alternative to hotel...  \n",
       "3  \\n\\nThis is a Much Better Alternative to Hotel...  \n",
       "4  \\n\\nThe Entire Suite is fully furnished. \\nThi...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "craiglist_sublet_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating empty containers for shared listing url's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_url = []                 # List of all the shared Url scraped from the website\n",
    "shared_listing_id = []          # List of all the craiglist listing id's scraped from each shared url\n",
    "shared_price = []               # List of all the price information scraped from each shared url\n",
    "shared_layout = []              # List of all the layout information scraped from each shared url\n",
    "shared_bedroom = []             # List of all the bedroom information scraped from each shared url\n",
    "shared_bathroom = []            # List of all the bathroom information scraped from each shared url\n",
    "shared_sqft = []                # List of all the square feet information scraped from each shared url\n",
    "shared_description = []         # List of all the description information scraped from each shared url\n",
    "shared_latitude = []            # List of all the latitude information scraped from each shared url\n",
    "shared_longitude = []           # List of all the longitude information scraped from each shared url\n",
    "shared_map_text = []            # List of all the map text information scraped from each shared url\n",
    "shared_google_map_url = []      # List of all the google map url information scraped from each shared url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scraping all the shared listing url's from shared_listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 17 shared url's scraped.\n",
      "There were 17 shared listing id's scraped.\n",
      "There were 17 shared price scraped.\n",
      "There were 17 shared layout scraped.\n",
      "There were 17 shared bedroom scraped.\n",
      "There were 17 shared bathroom scraped.\n",
      "There were 17 shared square feet scraped.\n",
      "There were 17 shared description scraped.\n",
      "There were 17 shared latitude scraped.\n",
      "There were 17 shared longitude scraped.\n",
      "There were 17 shared map text scraped.\n",
      "There were 17 shared google map url scraped.\n"
     ]
    }
   ],
   "source": [
    "# Scraping the content of each url on the search page from the shared listing   \n",
    "for sharedurl in range(len(shared_listing)):\n",
    "    information = listing_extractor(shared_listing[sharedurl])\n",
    "    shared_url.append(shared_listing[sharedurl])\n",
    "    \n",
    "    # Extracting the craiglist listing ID of each individual listing\n",
    "    try:\n",
    "        posting_info = information.find(\"div\", {\"class\":\"postinginfos\"})\n",
    "        locate_id = posting_info.find(\"p\",{\"class\":\"postinginfo\"})\n",
    "        id_only = re.findall(r'\\d+', locate_id.text)\n",
    "        result = '%s' % \"','\".join(id_only)\n",
    "        if result:\n",
    "            shared_listing_id.append(result)\n",
    "    except:\n",
    "        no_id = 'Missing_Data' \n",
    "        shared_listing_id.append(no_id)\n",
    "    \n",
    "    # Extracting the price of each individual listing\n",
    "    try:\n",
    "        price_info = information.find(\"span\", {\"class\":\"price\"}).string\n",
    "        only_price = re.findall(r'\\d+', price_info)\n",
    "        if only_price:\n",
    "            shared_price.append(only_price[0])\n",
    "    except:\n",
    "        no_price = 'Missing_Data'\n",
    "        shared_price.append(no_price)\n",
    "            \n",
    "    # Extracting the layout of each individual listing\n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        only_layout = layout_info[0].text\n",
    "        if only_layout:\n",
    "            shared_layout.append(only_layout)\n",
    "    except:\n",
    "        no_layout = 'Missing_Data'\n",
    "        shared_layout.append(no_layout)\n",
    "    \n",
    "    # Extracting the bedroom of each individual listing\n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        only_layout = layout_info[0].text\n",
    "        regex_layout = re.findall(r'\\d+', only_layout)\n",
    "        if regex_layout:\n",
    "            bedroom_info = regex_layout[0]\n",
    "            shared_bedroom.append(bedroom_info)\n",
    "    except:\n",
    "        no_bedroom = 'Missing_Data'\n",
    "        shared_bedroom.append(no_bedroom)\n",
    "        \n",
    "    # Extracting the bathroom of each individual listing\n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        only_layout = layout_info[0].text\n",
    "        regex_layout = re.findall(r'\\d+', only_layout)\n",
    "        if regex_layout:\n",
    "            bathroom_info = regex_layout[1]\n",
    "            shared_bathroom.append(bathroom_info)\n",
    "    except:\n",
    "        no_bathroom = 'Missing_Data'\n",
    "        shared_bathroom.append(no_bathroom)\n",
    "    \n",
    "    # Extracting the square feet of each individual listing \n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        squarefeet_info = layout_info[1].text\n",
    "        regex_sqft = re.findall(r'\\d{3,4}ft\\d', squarefeet_info)\n",
    "        if regex_sqft:\n",
    "            only_sqft = re.findall(r'\\d+', regex_sqft[0])\n",
    "            if only_sqft:\n",
    "                shared_sqft.append(only_sqft[0])\n",
    "        else:\n",
    "            try:\n",
    "                description_information = information.find(\"section\",\n",
    "                                                           {\"id\" :\"postingbody\"}).findAll(text=True,\n",
    "                                                                                          recursive=False)                          \n",
    "                description_info = ''.join(description_information)\n",
    "                initial_regex_search = re.findall(r'(\\d{3,4}|\\d+[\\,]?\\d+)[\\s]?[S|s][q|f]', description_info)\n",
    "                if initial_regex_search:\n",
    "                    shared_sqft.append(initial_regex_search[0])\n",
    "                else:\n",
    "                    second_regex_search = re.findall(r'\\w+[\\s]?\\w+[\\s]?:[\\s]?\\d+[-]?\\d+', description_info)\n",
    "                    if second_regex_search:\n",
    "                        regex_digits_only = re.findall(r'\\d+[-]?\\d+', second_regex_search)\n",
    "                        if regex_digits_only:\n",
    "                            shared_sqft.append(regex_digits_only[0])\n",
    "                        else:\n",
    "                            no_regex_digits = \"Missing_Data\"\n",
    "                            shared_sqft.append(no_regex_digits)\n",
    "                    else:\n",
    "                        no_second_regex_search = \"Missing_Data\"\n",
    "                        shared_sqft.append(no_second_regex_search)\n",
    "            except:\n",
    "                no_description = 'Missing_Data'\n",
    "                shared_sqft.append(no_description)\n",
    "    except:\n",
    "        no_listing = 'Missing_Data'\n",
    "        shared_sqft.append(no_listing)\n",
    "        \n",
    "    # Extracting the latitude of each individual listing\n",
    "    try:\n",
    "        location_info = information.find(\"div\",{\"class\": \"viewposting\"})\n",
    "        latitude_info = location_info.get(\"data-latitude\")\n",
    "        if latitude_info:\n",
    "            shared_latitude.append(latitude_info)\n",
    "    except:\n",
    "        no_latitude_info = 'Missing_Data'\n",
    "        shared_latitude.append(no_latitude_info)\n",
    "                \n",
    "    # Extracting the longitude of each individual listing    \n",
    "    try:\n",
    "        longitude_info = location_info.get(\"data-longitude\")\n",
    "        if longitude_info:\n",
    "            shared_longitude.append(longitude_info)\n",
    "    except:\n",
    "        no_longitude_info = 'Missing_Data'\n",
    "        shared_longitude.append(no_longitude_info)\n",
    "            \n",
    "    # Extracting the text below map of each individual listing\n",
    "    try:\n",
    "        map_text_info = information.find(\"div\",{\"class\":\"mapaddress\"})\n",
    "        only_map_text = map_text_info.text\n",
    "        if only_map_text:\n",
    "            shared_map_text.append(only_map_text)\n",
    "    except:\n",
    "        no_map_text = \"Missing_Data\"\n",
    "        shared_map_text.append(no_map_text)\n",
    "                \n",
    "    # Extracting the text below map of each individual listing\n",
    "    try:\n",
    "        google_map_url_info = information.find(\"p\",{\"class\":\"mapaddress\"})\n",
    "        only_google_map_url = google_map_url_info.find(\"a\").get(\"href\")\n",
    "        if only_google_map_url:\n",
    "            shared_google_map_url.append(only_google_map_url)\n",
    "    except:\n",
    "        no_google_map_url = 'Missing_Data'\n",
    "        shared_google_map_url.append(no_google_map_url)\n",
    "    \n",
    "    # Extracting the description of each individual listing \n",
    "    try:\n",
    "        description_information = information.find(\"section\",{\"id\" :\"postingbody\"}).findAll(text=True, recursive=False)                          \n",
    "        description_info = ''.join(description_information)\n",
    "        if description_info:\n",
    "            shared_description.append(description_info)\n",
    "    except:\n",
    "        no_description = \"Missing_Data\"\n",
    "        shared_description.append(no_description)\n",
    "    \n",
    "    sleep(2)\n",
    "\n",
    "print('There were %s shared url\\'s scraped.' % (len(shared_url)))\n",
    "print('There were %s shared listing id\\'s scraped.' % (len(shared_listing_id)))   \n",
    "print('There were %s shared price scraped.' % (len(shared_price)))\n",
    "print('There were %s shared layout scraped.' % (len(shared_layout)))\n",
    "print('There were %s shared bedroom scraped.' % (len(shared_bedroom))) \n",
    "print('There were %s shared bathroom scraped.' % (len(shared_bathroom)))\n",
    "print('There were %s shared square feet scraped.' % (len(shared_sqft)))\n",
    "print('There were %s shared description scraped.' % (len(shared_description)))\n",
    "print('There were %s shared latitude scraped.' % (len(shared_latitude)))\n",
    "print('There were %s shared longitude scraped.' % (len(shared_longitude))) \n",
    "print('There were %s shared map text scraped.' % (len(shared_map_text))) \n",
    "print('There were %s shared google map url scraped.' % (len(shared_google_map_url))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataframe using pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "craiglist_shared_dataset = pd.DataFrame(np.column_stack([shared_listing_id, shared_price, shared_layout, \n",
    "                                                         shared_bedroom, shared_bathroom, shared_sqft, \n",
    "                                                         shared_latitude, shared_longitude, shared_url, \n",
    "                                                         shared_map_text, shared_google_map_url, \n",
    "                                                         shared_description]),\n",
    "                                        columns = ['shared_listing_id','shared_price', 'shared_layout',\n",
    "                                                   'shared_bedroom', 'shared_bathroom', 'shared_sqft', \n",
    "                                                   'shared_latitude', 'shared_longitude', 'shared_url', \n",
    "                                                   'shared_map_text', 'shared_google_map_url', 'shared_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shared_listing_id</th>\n",
       "      <th>shared_price</th>\n",
       "      <th>shared_layout</th>\n",
       "      <th>shared_bedroom</th>\n",
       "      <th>shared_bathroom</th>\n",
       "      <th>shared_sqft</th>\n",
       "      <th>shared_latitude</th>\n",
       "      <th>shared_longitude</th>\n",
       "      <th>shared_url</th>\n",
       "      <th>shared_map_text</th>\n",
       "      <th>shared_google_map_url</th>\n",
       "      <th>shared_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6466160211</td>\n",
       "      <td>595</td>\n",
       "      <td>available feb 1</td>\n",
       "      <td>1</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/roo/d/roomma...</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>\\n\\nGreat apartment in Toronto. Its a 2 bedroo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6465918192</td>\n",
       "      <td>500</td>\n",
       "      <td>available jan 19</td>\n",
       "      <td>19</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>43.665906</td>\n",
       "      <td>-79.385854</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/roo/d/lookin...</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>https://maps.google.com/maps/preview/@43.66590...</td>\n",
       "      <td>\\n\\nI'm 35/m, looking for a female room mate t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6465974317</td>\n",
       "      <td>675</td>\n",
       "      <td>available feb 1</td>\n",
       "      <td>1</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>43.642946</td>\n",
       "      <td>-79.407386</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/roo/d/room-f...</td>\n",
       "      <td>801 king st west</td>\n",
       "      <td>https://maps.google.com/?q=loc%3A+%38%30%31+ki...</td>\n",
       "      <td>\\n\\nRoom Available for rent, Room is cozy and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6459430804</td>\n",
       "      <td>1500</td>\n",
       "      <td>available jan 14</td>\n",
       "      <td>14</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>43.644649</td>\n",
       "      <td>-79.523574</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/roo/d/amazin...</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>https://maps.google.com/maps/preview/@43.64464...</td>\n",
       "      <td>\\n\\nLocation location location!!\\n\\nI am looki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6458490025</td>\n",
       "      <td>750</td>\n",
       "      <td>available jan 13</td>\n",
       "      <td>13</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>43.670371</td>\n",
       "      <td>-79.405301</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/roo/d/furnis...</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>https://maps.google.com/maps/preview/@43.67037...</td>\n",
       "      <td>\\n\\nShared accommodation available immediately...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  shared_listing_id shared_price     shared_layout shared_bedroom  \\\n",
       "0        6466160211          595   available feb 1              1   \n",
       "1        6465918192          500  available jan 19             19   \n",
       "2        6465974317          675   available feb 1              1   \n",
       "3        6459430804         1500  available jan 14             14   \n",
       "4        6458490025          750  available jan 13             13   \n",
       "\n",
       "  shared_bathroom   shared_sqft shared_latitude shared_longitude  \\\n",
       "0    Missing_Data  Missing_Data    Missing_Data     Missing_Data   \n",
       "1    Missing_Data  Missing_Data       43.665906       -79.385854   \n",
       "2    Missing_Data  Missing_Data       43.642946       -79.407386   \n",
       "3    Missing_Data  Missing_Data       43.644649       -79.523574   \n",
       "4    Missing_Data  Missing_Data       43.670371       -79.405301   \n",
       "\n",
       "                                          shared_url   shared_map_text  \\\n",
       "0  https://toronto.craigslist.ca/tor/roo/d/roomma...      Missing_Data   \n",
       "1  https://toronto.craigslist.ca/tor/roo/d/lookin...      Missing_Data   \n",
       "2  https://toronto.craigslist.ca/tor/roo/d/room-f...  801 king st west   \n",
       "3  https://toronto.craigslist.ca/tor/roo/d/amazin...      Missing_Data   \n",
       "4  https://toronto.craigslist.ca/tor/roo/d/furnis...      Missing_Data   \n",
       "\n",
       "                               shared_google_map_url  \\\n",
       "0                                       Missing_Data   \n",
       "1  https://maps.google.com/maps/preview/@43.66590...   \n",
       "2  https://maps.google.com/?q=loc%3A+%38%30%31+ki...   \n",
       "3  https://maps.google.com/maps/preview/@43.64464...   \n",
       "4  https://maps.google.com/maps/preview/@43.67037...   \n",
       "\n",
       "                                  shared_description  \n",
       "0  \\n\\nGreat apartment in Toronto. Its a 2 bedroo...  \n",
       "1  \\n\\nI'm 35/m, looking for a female room mate t...  \n",
       "2  \\n\\nRoom Available for rent, Room is cozy and ...  \n",
       "3  \\n\\nLocation location location!!\\n\\nI am looki...  \n",
       "4  \\n\\nShared accommodation available immediately...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "craiglist_shared_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the DataFrame into Excel file to store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "craiglist_shared_dataset.to_excel(\"Final_Toronto_Craiglist_Condo_Shared_dataset_Jan_20.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating empty containers for sale listing url's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_url = []                 # List of all the sale Url scraped from the website\n",
    "sale_listing_id = []          # List of all the craiglist listing id's scraped from each sale url\n",
    "sale_price = []               # List of all the price information scraped from each sale url\n",
    "sale_layout = []              # List of all the layout information scraped from each sale url\n",
    "sale_bedroom = []             # List of all the bedroom information scraped from each sale url\n",
    "sale_bathroom = []            # List of all the bathroom information scraped from each sale url\n",
    "sale_sqft = []                # List of all the square feet information scraped from each sale url\n",
    "sale_description = []         # List of all the description information scraped from each sale url\n",
    "sale_latitude = []            # List of all the latitude information scraped from each sale url\n",
    "sale_longitude = []           # List of all the longitude information scraped from each sale url\n",
    "sale_map_text = []            # List of all the map text information scraped from each sale url\n",
    "sale_google_map_url = []      # List of all the google map url information scraped from each sale url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scraping all the sale listing url's from sale_listing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 662 sale url's scraped.\n",
      "There were 662 sale listing id's scraped.\n",
      "There were 662 sale price scraped.\n",
      "There were 662 sale layout scraped.\n",
      "There were 662 sale bedroom scraped.\n",
      "There were 662 sale bathroom scraped.\n",
      "There were 662 sale square feet scraped.\n",
      "There were 662 sale description scraped.\n",
      "There were 662 sale latitude scraped.\n",
      "There were 662 sale longitude scraped.\n",
      "There were 662 sale map text scraped.\n",
      "There were 662 sale google map url scraped.\n"
     ]
    }
   ],
   "source": [
    "# Scraping the content of each url on the search page from the sale listing   \n",
    "for saleurl in range(len(sale_listing)):\n",
    "    information = listing_extractor(sale_listing[saleurl])\n",
    "    sale_url.append(sale_listing[saleurl])\n",
    "    \n",
    "    # Extracting the craiglist listing ID of each individual listing\n",
    "    try:\n",
    "        posting_info = information.find(\"div\", {\"class\":\"postinginfos\"})\n",
    "        locate_id = posting_info.find(\"p\",{\"class\":\"postinginfo\"})\n",
    "        id_only = re.findall(r'\\d+', locate_id.text)\n",
    "        result = '%s' % \"','\".join(id_only)\n",
    "        if result:\n",
    "            sale_listing_id.append(result)\n",
    "    except:\n",
    "        no_id = 'Missing_Data' \n",
    "        sale_listing_id.append(no_id)\n",
    "    \n",
    "    # Extracting the price of each individual listing\n",
    "    try:\n",
    "        price_info = information.find(\"span\", {\"class\":\"price\"}).string\n",
    "        only_price = re.findall(r'\\d+', price_info)\n",
    "        if only_price:\n",
    "            sale_price.append(only_price[0])\n",
    "    except:\n",
    "        no_price = 'Missing_Data'\n",
    "        sale_price.append(no_price)\n",
    "            \n",
    "    # Extracting the layout of each individual listing\n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        only_layout = layout_info[0].text\n",
    "        if only_layout:\n",
    "            sale_layout.append(only_layout)\n",
    "    except:\n",
    "        no_layout = 'Missing_Data'\n",
    "        sale_layout.append(no_layout)\n",
    "    \n",
    "    # Extracting the bedroom of each individual listing\n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        only_layout = layout_info[0].text\n",
    "        regex_layout = re.findall(r'\\d+', only_layout)\n",
    "        if regex_layout:\n",
    "            bedroom_info = regex_layout[0]\n",
    "            sale_bedroom.append(bedroom_info)\n",
    "    except:\n",
    "        no_bedroom = 'Missing_Data'\n",
    "        sale_bedroom.append(no_bedroom)\n",
    "        \n",
    "    # Extracting the bathroom of each individual listing\n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        only_layout = layout_info[0].text\n",
    "        regex_layout = re.findall(r'\\d+', only_layout)\n",
    "        if regex_layout:\n",
    "            bathroom_info = regex_layout[1]\n",
    "            sale_bathroom.append(bathroom_info)\n",
    "    except:\n",
    "        no_bathroom = 'Missing_Data'\n",
    "        sale_bathroom.append(no_bathroom)\n",
    "    \n",
    "    # Extracting the square feet of each individual listing \n",
    "    try:\n",
    "        layout_info = information.findAll(\"span\", {\"class\":\"shared-line-bubble\"})\n",
    "        squarefeet_info = layout_info[1].text\n",
    "        regex_sqft = re.findall(r'\\d{3,4}ft\\d', squarefeet_info)\n",
    "        if regex_sqft:\n",
    "            only_sqft = re.findall(r'\\d+', regex_sqft[0])\n",
    "            if only_sqft:\n",
    "                sale_sqft.append(only_sqft[0])\n",
    "        else:\n",
    "            try:\n",
    "                description_information = information.find(\"section\",\n",
    "                                                           {\"id\" :\"postingbody\"}).findAll(text=True,\n",
    "                                                                                          recursive=False)                          \n",
    "                description_info = ''.join(description_information)\n",
    "                initial_regex_search = re.findall(r'(\\d{3,4}|\\d+[\\,]?\\d+)[\\s]?[S|s][q|f]', description_info)\n",
    "                if initial_regex_search:\n",
    "                    sale_sqft.append(initial_regex_search[0])\n",
    "                else:\n",
    "                    second_regex_search = re.findall(r'\\w+[\\s]?\\w+[\\s]?:[\\s]?\\d+[-]?\\d+', description_info)\n",
    "                    if second_regex_search:\n",
    "                        regex_digits_only = re.findall(r'\\d+[-]?\\d+', second_regex_search)\n",
    "                        if regex_digits_only:\n",
    "                            sale_sqft.append(regex_digits_only[0])\n",
    "                        else:\n",
    "                            no_regex_digits = \"Missing_Data\"\n",
    "                            sale_sqft.append(no_regex_digits)\n",
    "                    else:\n",
    "                        no_second_regex_search = \"Missing_Data\"\n",
    "                        sale_sqft.append(no_second_regex_search)\n",
    "            except:\n",
    "                no_description = 'Missing_Data'\n",
    "                sale_sqft.append(no_description)\n",
    "    except:\n",
    "        no_listing = 'Missing_Data'\n",
    "        sale_sqft.append(no_listing)\n",
    "        \n",
    "    # Extracting the latitude of each individual listing\n",
    "    try:\n",
    "        location_info = information.find(\"div\",{\"class\": \"viewposting\"})\n",
    "        latitude_info = location_info.get(\"data-latitude\")\n",
    "        if latitude_info:\n",
    "            sale_latitude.append(latitude_info)\n",
    "    except:\n",
    "        no_latitude_info = 'Missing_Data'\n",
    "        sale_latitude.append(no_latitude_info)\n",
    "                \n",
    "    # Extracting the longitude of each individual listing    \n",
    "    try:\n",
    "        longitude_info = location_info.get(\"data-longitude\")\n",
    "        if longitude_info:\n",
    "            sale_longitude.append(longitude_info)\n",
    "    except:\n",
    "        no_longitude_info = 'Missing_Data'\n",
    "        sale_longitude.append(no_longitude_info)\n",
    "            \n",
    "    # Extracting the text below map of each individual listing\n",
    "    try:\n",
    "        map_text_info = information.find(\"div\",{\"class\":\"mapaddress\"})\n",
    "        only_map_text = map_text_info.text\n",
    "        if only_map_text:\n",
    "            sale_map_text.append(only_map_text)\n",
    "    except:\n",
    "        no_map_text = \"Missing_Data\"\n",
    "        sale_map_text.append(no_map_text)\n",
    "                \n",
    "    # Extracting the text below map of each individual listing\n",
    "    try:\n",
    "        google_map_url_info = information.find(\"p\",{\"class\":\"mapaddress\"})\n",
    "        only_google_map_url = google_map_url_info.find(\"a\").get(\"href\")\n",
    "        if only_google_map_url:\n",
    "            sale_google_map_url.append(only_google_map_url)\n",
    "    except:\n",
    "        no_google_map_url = 'Missing_Data'\n",
    "        sale_google_map_url.append(no_google_map_url)\n",
    "    \n",
    "    # Extracting the description of each individual listing \n",
    "    try:\n",
    "        description_information = information.find(\"section\",{\"id\" :\"postingbody\"}).findAll(text=True, recursive=False)                          \n",
    "        description_info = ''.join(description_information)\n",
    "        if description_info:\n",
    "            sale_description.append(description_info)\n",
    "    except:\n",
    "        no_description = \"Missing_Data\"\n",
    "        sale_description.append(no_description)\n",
    "    \n",
    "    sleep(2)\n",
    "\n",
    "print('There were %s sale url\\'s scraped.' % (len(sale_url)))\n",
    "print('There were %s sale listing id\\'s scraped.' % (len(sale_listing_id)))   \n",
    "print('There were %s sale price scraped.' % (len(sale_price)))\n",
    "print('There were %s sale layout scraped.' % (len(sale_layout)))\n",
    "print('There were %s sale bedroom scraped.' % (len(sale_bedroom))) \n",
    "print('There were %s sale bathroom scraped.' % (len(sale_bathroom)))\n",
    "print('There were %s sale square feet scraped.' % (len(sale_sqft)))\n",
    "print('There were %s sale description scraped.' % (len(sale_description)))\n",
    "print('There were %s sale latitude scraped.' % (len(sale_latitude)))\n",
    "print('There were %s sale longitude scraped.' % (len(sale_longitude))) \n",
    "print('There were %s sale map text scraped.' % (len(sale_map_text))) \n",
    "print('There were %s sale google map url scraped.' % (len(sale_google_map_url))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataframe using pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "craiglist_sale_dataset = pd.DataFrame(np.column_stack([sale_listing_id, sale_price, sale_layout, \n",
    "                                                         sale_bedroom, sale_bathroom, sale_sqft, \n",
    "                                                         sale_latitude, sale_longitude, sale_url, \n",
    "                                                         sale_map_text, sale_google_map_url, \n",
    "                                                         sale_description]),\n",
    "                                        columns = ['sale_listing_id','sale_price', 'sale_layout',\n",
    "                                                   'sale_bedroom', 'sale_bathroom', 'sale_sqft', \n",
    "                                                   'sale_latitude', 'sale_longitude', 'sale_url', \n",
    "                                                   'sale_map_text', 'sale_google_map_url', 'sale_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sale_listing_id</th>\n",
       "      <th>sale_price</th>\n",
       "      <th>sale_layout</th>\n",
       "      <th>sale_bedroom</th>\n",
       "      <th>sale_bathroom</th>\n",
       "      <th>sale_sqft</th>\n",
       "      <th>sale_latitude</th>\n",
       "      <th>sale_longitude</th>\n",
       "      <th>sale_url</th>\n",
       "      <th>sale_map_text</th>\n",
       "      <th>sale_google_map_url</th>\n",
       "      <th>sale_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6466167559</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>2BR / 2Ba</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>43.711164</td>\n",
       "      <td>-79.726024</td>\n",
       "      <td>https://toronto.craigslist.ca/bra/reo/d/condo-...</td>\n",
       "      <td>8 Lisa st.#701</td>\n",
       "      <td>https://maps.google.com/?q=loc%3A+%38+Lisa+st%...</td>\n",
       "      <td>\\n\\n2 bed 2 full bath 1 park and locker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6461524938</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>1BR / 1Ba</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>43.642707</td>\n",
       "      <td>-79.382305</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/reb/d/downto...</td>\n",
       "      <td>65 Bremner Blvd.</td>\n",
       "      <td>https://maps.google.com/?q=loc%3A+%36%35+Bremn...</td>\n",
       "      <td>\\n\\nDIRECTLY CONNECTED to the AIR CANADA CENTR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6462079074</td>\n",
       "      <td>369000</td>\n",
       "      <td>1BR / 1Ba</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Missing_Data</td>\n",
       "      <td>43.613579</td>\n",
       "      <td>-79.560476</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/reb/d/high-p...</td>\n",
       "      <td>105 The Queensway</td>\n",
       "      <td>https://maps.google.com/?q=loc%3A+%31%30%35+Th...</td>\n",
       "      <td>\\n\\nGreat High Park First Time Buyer or Invest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6462122777</td>\n",
       "      <td>339900</td>\n",
       "      <td>2BR / 2Ba</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1150</td>\n",
       "      <td>43.697993</td>\n",
       "      <td>-79.511595</td>\n",
       "      <td>https://toronto.craigslist.ca/tor/reb/d/beauti...</td>\n",
       "      <td>3 Hickory Tree Rd.</td>\n",
       "      <td>https://maps.google.com/?q=loc%3A+%33+Hickory+...</td>\n",
       "      <td>\\n\\nGorgeous Spacious Condo Suitable for Downs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6462900930</td>\n",
       "      <td>335000</td>\n",
       "      <td>1BR / 1Ba</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>720</td>\n",
       "      <td>43.582317</td>\n",
       "      <td>-79.620920</td>\n",
       "      <td>https://toronto.craigslist.ca/mss/reb/d/missis...</td>\n",
       "      <td>115 Hillcrest Ave.</td>\n",
       "      <td>https://maps.google.com/?q=loc%3A+%31%31%35+Hi...</td>\n",
       "      <td>\\n\\nMississauga Great Investment  Condo \\nOne ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sale_listing_id    sale_price sale_layout sale_bedroom sale_bathroom  \\\n",
       "0      6466167559  Missing_Data   2BR / 2Ba            2             2   \n",
       "1      6461524938  Missing_Data   1BR / 1Ba            1             1   \n",
       "2      6462079074        369000   1BR / 1Ba            1             1   \n",
       "3      6462122777        339900   2BR / 2Ba            2             2   \n",
       "4      6462900930        335000   1BR / 1Ba            1             1   \n",
       "\n",
       "      sale_sqft sale_latitude sale_longitude  \\\n",
       "0  Missing_Data     43.711164     -79.726024   \n",
       "1           500     43.642707     -79.382305   \n",
       "2  Missing_Data     43.613579     -79.560476   \n",
       "3          1150     43.697993     -79.511595   \n",
       "4           720     43.582317     -79.620920   \n",
       "\n",
       "                                            sale_url       sale_map_text  \\\n",
       "0  https://toronto.craigslist.ca/bra/reo/d/condo-...      8 Lisa st.#701   \n",
       "1  https://toronto.craigslist.ca/tor/reb/d/downto...    65 Bremner Blvd.   \n",
       "2  https://toronto.craigslist.ca/tor/reb/d/high-p...   105 The Queensway   \n",
       "3  https://toronto.craigslist.ca/tor/reb/d/beauti...  3 Hickory Tree Rd.   \n",
       "4  https://toronto.craigslist.ca/mss/reb/d/missis...  115 Hillcrest Ave.   \n",
       "\n",
       "                                 sale_google_map_url  \\\n",
       "0  https://maps.google.com/?q=loc%3A+%38+Lisa+st%...   \n",
       "1  https://maps.google.com/?q=loc%3A+%36%35+Bremn...   \n",
       "2  https://maps.google.com/?q=loc%3A+%31%30%35+Th...   \n",
       "3  https://maps.google.com/?q=loc%3A+%33+Hickory+...   \n",
       "4  https://maps.google.com/?q=loc%3A+%31%31%35+Hi...   \n",
       "\n",
       "                                    sale_description  \n",
       "0        \\n\\n2 bed 2 full bath 1 park and locker      \n",
       "1  \\n\\nDIRECTLY CONNECTED to the AIR CANADA CENTR...  \n",
       "2  \\n\\nGreat High Park First Time Buyer or Invest...  \n",
       "3  \\n\\nGorgeous Spacious Condo Suitable for Downs...  \n",
       "4  \\n\\nMississauga Great Investment  Condo \\nOne ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "craiglist_sale_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the DataFrame into Excel file to store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "craiglist_sale_dataset.to_excel(\"Final_Toronto_Craiglist_Condo_Sale_dataset_Jan_20.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
